"use strict";(self.webpackChunkmirzafahmi_github_io=self.webpackChunkmirzafahmi_github_io||[]).push([[8130],{7735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"accidentally-use-redis","metadata":{"permalink":"/blog/accidentally-use-redis","source":"@site/blog/2025-11-27-redis/index.md","title":"How I accidentally use Redis (sort of)","description":"Redis. I bet every software developer has heard of or used Redis in their project at some point. Or learn about it at least for the technical interview. However, not many have had the chance to use or utilize it as I have. Up to this point, I just know that Redis is an in-memory key-value store that can be used to implement queues and pub/sub messaging. Let me re-catch what Redis is. Redis is an open-source, in-memory, NoSQL key-value store used as a database, cache, and message broker. It\'s  an all-around software that can be used to cache or even as a  database (please don\'t do this).","date":"2025-11-27T00:00:00.000Z","tags":[],"readingTime":3.42,"hasTruncateMarker":true,"authors":[{"name":"Ahmad Mirza Fahmi","title":"Backend Software Engineer","socials":{"linkedin":"https://www.linkedin.com/in/mirzafahmi/","github":"https://github.com/mirzafahmi"},"imageURL":"https://github.com/mirzafahmi.png","key":"amf","page":null}],"frontMatter":{"slug":"accidentally-use-redis","title":"How I accidentally use Redis (sort of)","authors":["amf"],"tags":[]},"unlisted":false,"nextItem":{"title":"What made me start programming?","permalink":"/blog/what-made-me-start-programming"}},"content":"Redis. I bet every software developer has heard of or used Redis in their project at some point. Or learn about it at least for the technical interview. However, not many have had the chance to use or utilize it as I have. Up to this point, I just know that Redis is an in-memory key-value store that can be used to implement queues and pub/sub messaging. Let me re-catch what Redis is. Redis is an open-source, in-memory, NoSQL key-value store used as a database, cache, and message broker. It\'s  an all-around software that can be used to cache or even as a  database (please don\'t do this).\\n\\n## Redis help increase my API performance\\n\\n- **0\u20131s \u2014 Instant Response:** Users expect immediate feedback or they assume the app is broken.\\n- **1\u20133s \u2014 Acceptable Wait:** Users tolerate a short delay if a loader or animation is shown.\\n- **3\u20137s \u2014 Attention Drift:** Users start losing focus and may shift attention elsewhere.\\n- **7\u201315s \u2014 Drop-Off Zone:** Most users abandon the task unless it\u2019s very important.\\n- **15s+ \u2014 Abandonment:** Users fully disengage and won\u2019t return to the action.\\n\\n\x3c!-- truncate --\x3e\\n\\nIn my latest project, I encountered terrible performance on one of my API, which took almost 10 seconds to response due to media upload to the storage bucket. A brief stack about this project, it uses Python, Django, and Django Rest Framework as part of the backend which is mostly synchronous, so async support is limited without external tools. It is not acceptable for modern apps as it falls under \\"Drop-Off Zone\\" so I plan to handle the media upload in the background. Then I encountered one of the solution to use a queue like Redis. But Redis alone is not enough to handle background tasks reliably, that is why a worker like django_rq is required to execute the task.\\n\\n![My Image](./django_rq.jpg)\\n\\nI choose Redis due to its simplicity to set up and ease of integration with django using django_rq. It is also lightweight and suitable for my project due to server resource constraints. So I converted the  method related to the media upload into \\"task\\" using the django_rq packages. During the process, I also learn that uploading a big file can be broken into smaller chunks which makes the upload process more reliable so that if one of the chunks fails to upload, only that chunk will get retried instead whole file. It also reduces memory load, which is a big plus in my context due to limited server resource. Lastly, it also improve the user experience as it can give real-time progress feedback.\\n\\n## It is easy to setup and run \\n\\nIt can be deployed using docker-compose along with django server. This setup will be run with one worker.\\n\\n```yaml\\nversion: \\"3.8\\"\\n\\nservices:\\n  redis:\\n    image: redis:7-alpine\\n    volumes:\\n      - redis_data:/data\\n    command: redis-server --bind 0.0.0.0 --requirepass testredis --protected-mode yes\\n\\n  web:\\n    build: .\\n    ports:\\n      - \\"80:8000\\"\\n    env_file:\\n      - .env\\n    environment:\\n      - REDIS_URL=redis://:testredis@redis:6379/0\\n    depends_on:\\n      - redis\\n    command: >\\n      sh -c \\"python manage.py rqworker default & \\n             python manage.py runserver 0.0.0.0:8000\\"\\n\\nvolumes:\\n  redis_data:\\n```\\n\\nAnd you have this kind of API with method that handle something in background.\\n\\n```python\\ndef process_file_background(filename):\\n    # simulate long processing\\n    time.sleep(10)\\n    print(f\\"Finished processing file: {filename}\\")\\n    return f\\"{filename} processed!\\"\\n\\n@api_view([\\"POST\\"])\\ndef upload_file(request):\\n    filename = request.data.get(\\"filename\\", \\"unknown.txt\\")\\n\\n    queue = django_rq.get_queue(\\"default\\")\\n    job = queue.enqueue(process_file_background, filename)\\n\\n    return Response({\\n        \\"message\\": \\"File received. Processing in background...\\",\\n        \\"job_id\\": job.id,\\n    })\\n```\\nThe server response will immediately return with 200 status while handling the task in the background as `queue.enqueue()` will handle called function in the background. Without this solution, my server will be blocked and take time to response for at least for 10 seconds.\\n\\n## Wrapping Up\\n\\nBy combining Redis with django_rq, I was able to move slow, blocking operations into background workers without rewriting my entire stack to async. The performance improvement was immediate, the user experience became smoother, and the overall system became more reliable. It\u2019s not the only solution but for Django projects with limited resources, it is definitely one of the most practical ones."},{"id":"what-made-me-start-programming","metadata":{"permalink":"/blog/what-made-me-start-programming","source":"@site/blog/2025-06-09-start/index.md","title":"What made me start programming?","description":"It all started in June 2022 at my last job, I guess. At that time, I had already been at my first job for over a year. The main business of the company was manufacturing medical devices \u2014 one of the top players in Malaysia too.","date":"2025-06-09T00:00:00.000Z","tags":[{"inline":false,"label":"Dev Story","permalink":"/blog/tags/dev-story","description":"Development Story"},{"inline":false,"label":"Motivation","permalink":"/blog/tags/motivation"},{"inline":false,"label":"Programming Journey","permalink":"/blog/tags/programming-journey"}],"readingTime":9.76,"hasTruncateMarker":true,"authors":[{"name":"Ahmad Mirza Fahmi","title":"Backend Software Engineer","socials":{"linkedin":"https://www.linkedin.com/in/mirzafahmi/","github":"https://github.com/mirzafahmi"},"imageURL":"https://github.com/mirzafahmi.png","key":"amf","page":null}],"frontMatter":{"slug":"what-made-me-start-programming","title":"What made me start programming?","authors":["amf"],"tags":["dev-story","motivation","programming-journey"]},"unlisted":false,"prevItem":{"title":"How I accidentally use Redis (sort of)","permalink":"/blog/accidentally-use-redis"}},"content":"It all started in June 2022 at my last job, I guess. At that time, I had already been at my first job for over a year. The main business of the company was manufacturing medical devices \u2014 one of the top players in Malaysia too.\\nDue to the nature of the small-medium enterprise (SME), most of us were assigned multiple portfolios, including me and the most senior staff member there. He had also been my desk neighbor for the duration I had been working there.\\n\\n## _\\"There Must Be a Better Way to Do That\\"_ Moment\\n\\nOne day during the peak of COVID cases around the world, test kits for COVID were limited. There was an influx in demand domestically and internationally. We got some orders from Hong Kong or Taiwan, if I\'m not mistaken. But to properly pass customs clearance and deliver to the customer, each carton of that particular test kit had to be attached with 2 documents: a commercial invoice (CI) and packing list (PL). The tricky part was that if we had 40 cartons for shipment, 40 sets of documents had to be generated. It might seem like just 40 sets, but it took over 2 hours, resulting in teary, red eyes and neck pain for my colleague to finish that task. Yes, the document generation relied on Microsoft Excel as a template, with values manually changed for each customer.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Programming Journey Begins\\n\\nOn my way home, I thought about that encounter and started googling about the issue once I reached home. During that time, there was no ChatGPT yet, so I just relied on knowledge scattered around the web. One solution was using a built-in approach in Microsoft Excel called `Range Names`, if I\'m not mistaken. It did the work, but there was one issue with that approach \u2014 I needed to manually save the generated documents one by one, which was tedious to me.\\n\\n#### But I Wasn\'t Satisfied with That Way of Doing Things\\n\\nThen I started with another solution using `Python`, `Pandas`, `Openpyxl`, and `Win32com` specifically. During that time, I had some coding knowledge in `JavaScript`, but mostly in the frontend spectrum. So, I just copied and pasted scripts that I randomly found on the web, without understanding or learning `Python` during that time. I just changed some parts of the code by trial and error until I got the results I wanted. My plan for that script was to read a customer list Excel file and map the info with the document Excel template, then save the generated documents as PDFs.\\n\\n#### The Feel of First Dopamine Hit from Coding\\n\\nAfter hours of trial and error, my script worked and successfully generated 40 sets of documents with just one command. Not just that \u2014 the generated documents were also saved with customer names in PDF format. At that moment, I felt something more significant than when I first started learning programming. When I first learned programming, I mostly learned about the frontend spectrum. It just felt like something was missing, as it lacked functionality, something that could help solve real problems I faced in real life. It\'s not that I\'m saying learning frontend/web development is a waste of time, but it just feels incomplete without the backend.\\n\\nWith backend development, I began to understand how data moves, how logic is processed, and how real-world problems can be automated and scaled. It gave me a sense of control and purpose that frontend alone hadn\u2019t fully delivered. That experience sparked a shift in my mindset \u2014 from building interfaces to building solutions. It was the first time I saw programming not just as code, but as a powerful tool to solve meaningful problems with real impact.\\n\\n#### From 2 Hours of Work Reduced to Just Merely 1 Minute...\\n\\nA short while after that event, there was another order from the same country. Without hesitation, I offered to help my colleague test the script that I made. I made some adjustments to the customer list to ensure the column names in the Microsoft Excel file were compatible with my script, then voila... With one command, taking merely 1 minute (ignoring the customer list file adjustment), 40 sets of documents were generated and saved in PDF format, ready to be printed. I felt the high that fellow programmers chase, I guess. Yes, I know if you include the customer list file adjustment, it could take around 5-10 minutes, but that\'s still ~90% time savings. Then, that script was also used for other similar orders, and I made some final modifications plus created a `Bash` script to make it easier for my colleague to use with just one click. I passed that script to my colleague before I left the company, and it\'s still being used there (hopefully).\\n\\n## It Didn\'t Stop There\\n\\nI started learning `Python` from scratch, mainly through YouTube and freeCodeCamp courses. I spent at least 1 hour per day on weekdays and 2-4 hours on weekends consistently. The process went smoothly due to my prior knowledge of `JavaScript`. Then I had big plans to use the power of my new knowledge in `Python` to make my day-to-day job easier.\\n\\nAnother script was made, this time related to summarizing sales reports generated from accounting software in `csv` format. Well, it was easy to do as `Python` has an excellent library named `Pandas` that does well in data cleaning and analysis. Previously, during my time learning `JavaScript`, I had a hard time understanding OOP, Class, constructor, etc. But this time, I stumbled upon a use case for OOP, where I needed to create modules for that script so I could reuse it to read, clean and summarize the sales report based on quartely interval. Learning anything is so much better when you have a situation to use it. Then, whenever I needed to see sales patterns or do sales forecasting for restocking, it was just one click away. I experimented with various modules I made to summarize based on brand, product, customer, etc.\\n\\n## Day-to-Day Job Got Easier\\n\\nI got comfortable with my `Python` skills and started working on a bigger dream project that I wanted to do during that time, which was to digitalize and automate the raw material inventory that fell under my portfolio. I started small, converting physical records from a pen and paper method to digital records in Microsoft Excel/Google Sheets. Note that during that time, I didn\'t know anything about other backend technology stacks and database technology. So technically, Microsoft Excel/Google Sheets were both frontend and database to me. During that time, I was okay with that as I wanted to gradually change things, and other people involved in keeping records were more familiar with that compared to if I introduced a new way of keeping records.\\n\\nThe records were kept based on products, with each file having multiple sheets based on their components and batches. Let\'s say if a product had 5 components, and 3 of those components had 2 batches, the total would be 8 sheets. At times, we had up to 20 sheets just for one product. Imagine having to manually open it to do a summary or, worse, handle an urgent inquiry from the sales team.\\n\\n#### Why Were Inquiries from the Sales Team Considered Worst-Case Scenarios?\\n\\nThis was one of the reasons why I wanted to digitize this inventory system. If I were late in responding to the sales team regarding their inquiry, we could lose sales, and my boss would come looking for me. Need to remind you again that I handled multiple portfolios, so sometimes I couldn\'t respond to inquiries quickly, and even when I wanted to, it could take some time depending on the level of inquiry.\\n\\nThus, I spent hours of my free time, on weekdays and weekends, creating these scripts. With just `Python`, `Pandas`, and some numpy, my ultimate dream at that time was born. Now, with just one command in the terminal, I could summarize all of our available products that were ready to produce. I also upgraded it to integrate with Google Sheets for the warehouse stock list so all other stakeholders could access it. During this, I learned deeper about Object Oriented Programming (OOP), `Pandas` DataFrame, dynamic variable names in class, etc. Yes, I never thought we could make variable names dynamic. Those scripts boosted my and my colleagues\' productivity drastically because they not only helped the sales team but also helped the procurement and accounting teams. For the accounting team, these scripts helped with accessing the current assets (at least for raw material inventory stock) for audit purposes, while for the procurement team, they helped in offsetting the forecasting values made in other scripts, so the forecast would take the raw material stock into account.\\n\\nOther than that, I also created a Telegram bot for the sales team\'s use. The reason was that every day, I got tons of chats from them asking about delivery charges for certain products to certain places. So, I made a bot for them to just input the quantity of product brands (because most of our products followed standardized brand packaging) and destination, whether to Peninsular Malaysia or East Malaysia. But one shortcoming was that I didn\'t have any knowledge of DevOps during that time, so I just hosted my bot locally and was only able to deploy or run it during office hours. Well, at least part of the problem was solved, even with just basic bots.\\n\\n#### Scripts Are Not Sustainable\\n\\nOne and a half months before my last day at that company, I found it difficult to pass my scripts to my successor. This was because my scripts relied on some programming knowledge to work with and to add new products if applicable. So I start to build the CMS style webapp using `Django`, with some `jQuery` for better user experience. My plan to make the webapp become centralized documention for production department to log their raw material stock inventory and I also create for IT department to centralized the assets documentation for company laptops etc. Due to time constraint, I was only able create basic functionality that comparable with current system of Excel/Google sheet with `Python` script, but not as the full version that I planned to create. Also during that time, I did not have any experience in deployment/DevOps, so I just deploy in one desktop that we used as server for accounting software but it is enough for other colleagues to access it if they connected to the company wifi/network.\\n\\n## Building with Purpose: The Start of Something Bigger\\n\\nLooking back, the experience taught me far more than just writing scripts or building web applications \u2014 it gave me a deeper understanding of how technology can create real, lasting impact within a team or company. From struggling with manual tasks to automating workflows and building tools for others, I began to see how code could scale solutions beyond myself. Although I couldn\u2019t complete everything I envisioned, the progress I made \u2014 from isolated scripts to a multi-user webapp \u2014 marked a turning point in my journey as a developer. It solidified my interest in backend development, system design, and solving practical problems through software. More importantly, it showed me that even small, imperfect steps can lead to meaningful change \u2014 and that\u2019s what continues to drive me forward. \\n\\n> **\\"Start where you are. Use what you have. Do what you can.\\"**\\n>\\n> \u2014 _Arthur Ashe_\\n\\nAnd that\u2019s how a simple need to save time opened the door to a career path I never imagined.\\nSo\u2026 what real-world problem will your first line of code solve?"}]}}')}}]);